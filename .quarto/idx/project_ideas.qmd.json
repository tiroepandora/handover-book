{"title":"Project Ideas","markdown":{"yaml":{"title":"Project Ideas","format":"html"},"headingText":"Dashboard Optimization","containsRefs":false,"markdown":"\n\nBelow are some project ideas that could be useful for the team or for your own learning. These are suggestions—feel free to pick up any that interest you.\n\n---\n\n\nI have started working on optimizing dashboard loading times, especially for **All Tides Rise (ATR)**. After analyzing the loading times, I identified the main contributors to slow performance.\n\n### What has been done so far\n\n- **Performance Analysis:**  \n    I analyzed dashboard loading times and identified bottlenecks. You can run your own performance analysis using the Power BI Performance Analyzer to see which visuals or queries take the most time to load.  \n    _A performance report (JSON file) will be linked for reference._\n\n    ![Performance Analyzer](references/PowerBIPerformanceData.json)\n\n- **Backend Optimization:**  \n    Calculations (e.g., 4-week averages, 12-week averages, long table filtering) were previously handled within Power BI, which slowed down performance. I have started moving these calculations and aggregations to BigQuery, using SQL scripts and views.  \n    For example, brand and category interest data are now calculated in BigQuery and pulled directly into Power BI, resulting in a more efficient data model and faster loading times.\n\n- **Data Model Cleanup:**  \n    During development, redundant measures often accumulate in the Power BI data model. I have started deleting unused measures (about 30% so far) in the ATR model.  \n    I used Tabular Editor to identify all measures and then manually checked if they were used in visuals, as Tabular Editor is mainly backend-focused and cannot fully analyze frontend usage.  \n    _I have documented my steps and will link a file so you can continue this work._\n\n    ![Tabular Editor Measure Cleanup](references/MeasuresWithTables.csv)\n\n#### Opportunities for further work\n\n- Continue cleaning up unused measures in ATR and other dashboards.\n- Explore optimizing other dashboards, though ATR is currently the most complex.\n- Use Tabular Editor and C# scripts to work with the data model (see the chapter on Tabular Editor for more details).\n- Consider moving additional heavy calculations and aggregations outside of Power BI.\n\n---\n\n## General Recommendations\n\n- Moving heavy calculations and aggregations outside of Power BI will benefit future projects.\n- Tomas is investigating a long-term migration from BigQuery (currently used only by our team) to Databricks, the company-wide data warehouse.  \n    BigQuery gives us full ownership and admin rights, but requires manual data maintenance.  \n    Databricks will be a more sustainable, company-wide solution, though the migration timeline is still unclear.  \n    _Keep this in mind for future projects._\n\n---\n\n## Automation of Operational Tasks\n\n- Automating repetitive operational tasks is definitely worthwhile.\n- Manual logins can make automation challenging.\n- I have experimented with different solutions using API keys (e.g., Google Search, Adobe Analytics, Asana).  \n    I was successful with Asana, but other APIs may require more setup or are not compatible with our environment.\n- I encourage you to explore automation opportunities—these tasks recur weekly and can become tedious over time.  \n    Making them smarter and more efficient will save time in the long run.\n\n---\n\n## Using Predictive Analytics for Measurement Efforts\n\nI have had a class on predictive analytics. Predictive analytics can enhance our measurement efforts by providing deeper insights and more accurate forecasts. By leveraging historical data and advanced algorithms, we can identify trends, anticipate outcomes, and make data-driven decisions.\n\n> **Tip:**  \n> If you are interested in exploring predictive analytics—such as forecasting, anomaly detection, or advanced modeling—reach out to Kasper.  \n> He is open to discussing ideas and would welcome collaboration on integrating these techniques into our measurement work.\n\n---\n\n## Leveraging AI and Machine Learning\n\nRecently, we completed a project leveraging AI for content classification—including images, articles, and videos—using Vertex AI and BigQuery. This initiative provided valuable insights into how large language models (LLMs) can accelerate workflows and unlock new efficiencies.\n\n> The experience highlighted both the power and potential of AI-driven solutions for our team.  \n> If you're interested, I can share the presentation we delivered to the broader group, which covers our approach and key learnings.\n\n[AI Project Presentation](https://pandoranet-my.sharepoint.com/:p:/r/personal/tiroe_pandora_net/Documents/Update%20Thursday.pptx?d=w56ed1d0a1b2841b9bfb812996bc10f38&csf=1&web=1&e=OyI4uI) <!-- Update with actual path -->\n\n[Code File](https://pandoranet-my.sharepoint.com/:u:/g/personal/tozdy_pandora_net/EUV7Kp8kS8lJhF51LS6PeZsB0R7HReJOf-YmUDkR7_YgKw?e=zcgLMp)\n\n\nExploring LLMs was both impactful and enjoyable, and I believe there are many more opportunities where these technologies could benefit our work.  \nIf you're interested in applying AI or machine learning to future projects, I encourage you to get involved—there is significant potential for innovation and impact within the team.\n\n---\n\n## Centralized Documentation for Data Processes\n\n**Proposal:**  \nSet up a structured documentation space in Confluence to serve as the single source of truth for our data processes.  \nThis would include:\n\n- Data pipeline overviews and architecture diagrams\n- Documentation of recurring data tasks and their owners\n- Guides for onboarding new team members to our data stack\n- Standard operating procedures for data ingestion, transformation, and reporting\n- Troubleshooting guides and FAQs\n\n **Benefits:**  \n- Reduces onboarding time for new team members  \n- Minimizes knowledge loss when people transition roles  \n- Improves consistency and quality of our data work  \n- Makes it easier to identify and address process gaps\n\nIf you are interested in knowledge management, technical writing, or improving team efficiency, this is a high-impact project that will benefit everyone.","srcMarkdownNoYaml":"\n\nBelow are some project ideas that could be useful for the team or for your own learning. These are suggestions—feel free to pick up any that interest you.\n\n---\n\n## Dashboard Optimization\n\nI have started working on optimizing dashboard loading times, especially for **All Tides Rise (ATR)**. After analyzing the loading times, I identified the main contributors to slow performance.\n\n### What has been done so far\n\n- **Performance Analysis:**  \n    I analyzed dashboard loading times and identified bottlenecks. You can run your own performance analysis using the Power BI Performance Analyzer to see which visuals or queries take the most time to load.  \n    _A performance report (JSON file) will be linked for reference._\n\n    ![Performance Analyzer](references/PowerBIPerformanceData.json)\n\n- **Backend Optimization:**  \n    Calculations (e.g., 4-week averages, 12-week averages, long table filtering) were previously handled within Power BI, which slowed down performance. I have started moving these calculations and aggregations to BigQuery, using SQL scripts and views.  \n    For example, brand and category interest data are now calculated in BigQuery and pulled directly into Power BI, resulting in a more efficient data model and faster loading times.\n\n- **Data Model Cleanup:**  \n    During development, redundant measures often accumulate in the Power BI data model. I have started deleting unused measures (about 30% so far) in the ATR model.  \n    I used Tabular Editor to identify all measures and then manually checked if they were used in visuals, as Tabular Editor is mainly backend-focused and cannot fully analyze frontend usage.  \n    _I have documented my steps and will link a file so you can continue this work._\n\n    ![Tabular Editor Measure Cleanup](references/MeasuresWithTables.csv)\n\n#### Opportunities for further work\n\n- Continue cleaning up unused measures in ATR and other dashboards.\n- Explore optimizing other dashboards, though ATR is currently the most complex.\n- Use Tabular Editor and C# scripts to work with the data model (see the chapter on Tabular Editor for more details).\n- Consider moving additional heavy calculations and aggregations outside of Power BI.\n\n---\n\n## General Recommendations\n\n- Moving heavy calculations and aggregations outside of Power BI will benefit future projects.\n- Tomas is investigating a long-term migration from BigQuery (currently used only by our team) to Databricks, the company-wide data warehouse.  \n    BigQuery gives us full ownership and admin rights, but requires manual data maintenance.  \n    Databricks will be a more sustainable, company-wide solution, though the migration timeline is still unclear.  \n    _Keep this in mind for future projects._\n\n---\n\n## Automation of Operational Tasks\n\n- Automating repetitive operational tasks is definitely worthwhile.\n- Manual logins can make automation challenging.\n- I have experimented with different solutions using API keys (e.g., Google Search, Adobe Analytics, Asana).  \n    I was successful with Asana, but other APIs may require more setup or are not compatible with our environment.\n- I encourage you to explore automation opportunities—these tasks recur weekly and can become tedious over time.  \n    Making them smarter and more efficient will save time in the long run.\n\n---\n\n## Using Predictive Analytics for Measurement Efforts\n\nI have had a class on predictive analytics. Predictive analytics can enhance our measurement efforts by providing deeper insights and more accurate forecasts. By leveraging historical data and advanced algorithms, we can identify trends, anticipate outcomes, and make data-driven decisions.\n\n> **Tip:**  \n> If you are interested in exploring predictive analytics—such as forecasting, anomaly detection, or advanced modeling—reach out to Kasper.  \n> He is open to discussing ideas and would welcome collaboration on integrating these techniques into our measurement work.\n\n---\n\n## Leveraging AI and Machine Learning\n\nRecently, we completed a project leveraging AI for content classification—including images, articles, and videos—using Vertex AI and BigQuery. This initiative provided valuable insights into how large language models (LLMs) can accelerate workflows and unlock new efficiencies.\n\n> The experience highlighted both the power and potential of AI-driven solutions for our team.  \n> If you're interested, I can share the presentation we delivered to the broader group, which covers our approach and key learnings.\n\n[AI Project Presentation](https://pandoranet-my.sharepoint.com/:p:/r/personal/tiroe_pandora_net/Documents/Update%20Thursday.pptx?d=w56ed1d0a1b2841b9bfb812996bc10f38&csf=1&web=1&e=OyI4uI) <!-- Update with actual path -->\n\n[Code File](https://pandoranet-my.sharepoint.com/:u:/g/personal/tozdy_pandora_net/EUV7Kp8kS8lJhF51LS6PeZsB0R7HReJOf-YmUDkR7_YgKw?e=zcgLMp)\n\n\nExploring LLMs was both impactful and enjoyable, and I believe there are many more opportunities where these technologies could benefit our work.  \nIf you're interested in applying AI or machine learning to future projects, I encourage you to get involved—there is significant potential for innovation and impact within the team.\n\n---\n\n## Centralized Documentation for Data Processes\n\n**Proposal:**  \nSet up a structured documentation space in Confluence to serve as the single source of truth for our data processes.  \nThis would include:\n\n- Data pipeline overviews and architecture diagrams\n- Documentation of recurring data tasks and their owners\n- Guides for onboarding new team members to our data stack\n- Standard operating procedures for data ingestion, transformation, and reporting\n- Troubleshooting guides and FAQs\n\n **Benefits:**  \n- Reduces onboarding time for new team members  \n- Minimizes knowledge loss when people transition roles  \n- Improves consistency and quality of our data work  \n- Makes it easier to identify and address process gaps\n\nIf you are interested in knowledge management, technical writing, or improving team efficiency, this is a high-impact project that will benefit everyone."},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"output-file":"project_ideas.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.6.42","theme":["default","styles.scss"],"title":"Project Ideas"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}